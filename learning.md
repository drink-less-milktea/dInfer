# dInfer æ¡†æ¶ç³»ç»Ÿå­¦ä¹ è·¯çº¿

> æœ¬æ–‡æ¡£æä¾›ä¸€ä¸ªå¾ªåºæ¸è¿›çš„å­¦ä¹ è·¯çº¿ï¼Œå¸®åŠ©ä½ æ·±å…¥ç†è§£ dInfer æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆDiffusion Language Models, dLLMsï¼‰æ¨ç†æ¡†æ¶ã€‚

---

## ğŸ“š ç›®å½•

1. [æ¡†æ¶æ¦‚è§ˆ](#æ¡†æ¶æ¦‚è§ˆ)
2. [å‰ç½®çŸ¥è¯†](#å‰ç½®çŸ¥è¯†)
3. [é¡¹ç›®ç»“æ„è¯¦è§£](#é¡¹ç›®ç»“æ„è¯¦è§£)
4. [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
5. [å­¦ä¹ è·¯çº¿](#å­¦ä¹ è·¯çº¿)
6. [å®è·µé¡¹ç›®](#å®è·µé¡¹ç›®)
7. [è¿›é˜¶ä¸»é¢˜](#è¿›é˜¶ä¸»é¢˜)
8. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ¯ æ¡†æ¶æ¦‚è§ˆ

### dInfer æ˜¯ä»€ä¹ˆï¼Ÿ

dInfer æ˜¯ä¸€ä¸ªé«˜æ•ˆã€å¯æ‰©å±•çš„**æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆDiffusion Language Models, dLLMsï¼‰**æ¨ç†æ¡†æ¶ï¼Œç”± inclusionAI å¼€å‘ã€‚ä¸ä¼ ç»Ÿçš„è‡ªå›å½’è¯­è¨€æ¨¡å‹ä¸åŒï¼Œæ‰©æ•£è¯­è¨€æ¨¡å‹é‡‡ç”¨è¿­ä»£å»å™ªçš„æ–¹å¼ç”Ÿæˆæ–‡æœ¬ï¼Œå¯ä»¥å®ç°**å¹¶è¡Œè§£ç **ï¼Œå¤§å¹…æå‡æ¨ç†é€Ÿåº¦ã€‚

### æ ¸å¿ƒç‰¹ç‚¹

- **æ¨¡å—åŒ–è®¾è®¡**: å°†æ¨ç†è¿‡ç¨‹åˆ†è§£ä¸º 4 ä¸ªç‹¬ç«‹ç»„ä»¶ï¼Œä¾¿äºç®—æ³•ç»„åˆå’Œæ‰©å±•
- **å¤šç§ç®—æ³•**: æ”¯æŒå¤šç§è§£ç ç­–ç•¥ï¼ˆThresholdã€Hierarchyã€Creditï¼‰å’Œç¼“å­˜æœºåˆ¶ï¼ˆPrefixã€Dualã€Vicinityï¼‰
- **é«˜æ€§èƒ½ä¼˜åŒ–**: 
  - å¼ é‡å¹¶è¡Œï¼ˆTPï¼‰å’Œä¸“å®¶å¹¶è¡Œï¼ˆEPï¼‰
  - åŠ¨æ€æ‰¹å¤„ç†ï¼ˆDynamic Batchingï¼‰
  - PyTorch ç¼–è¯‘å’Œ CUDA Graphs
  - å¾ªç¯å±•å¼€ï¼ˆLoop Unrollingï¼‰æ¶ˆé™¤ CUDA æµæ°”æ³¡
- **æ”¯æŒå¤šæ¨¡å‹**: LLaDAã€LLaDA-MoEã€LLaDA2ï¼ˆåŒ…æ‹¬ mini å’Œ flash ç‰ˆæœ¬ï¼‰
- **é«˜ååé‡**: åœ¨ HumanEval ä¸Šå•æ ·æœ¬è¶…è¿‡ 1100 TPSï¼Œæ¯” Fast-dLLM å¿« 10 å€

### å››å¤§æ ¸å¿ƒç»„ä»¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              dInfer æ¶æ„è®¾è®¡                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Model (æ¨¡å‹å±‚)                                 â”‚
â”‚     â€¢ LLaDA: 8B å‚æ•°çš„æ‰©æ•£è¯­è¨€æ¨¡å‹                 â”‚
â”‚     â€¢ LLaDA-MoE: 7B å‚æ•°çš„ MoE æ‰©æ•£æ¨¡å‹            â”‚
â”‚     â€¢ LLaDA2: 16B-100B çš„å—æ‰©æ•£æ¨¡å‹                â”‚
â”‚                                                     â”‚
â”‚  2. Diffusion Iteration Manager (è¿­ä»£ç®¡ç†å™¨)       â”‚
â”‚     â€¢ BlockWise: å—çº§é€æ­¥ç”Ÿæˆ                      â”‚
â”‚     â€¢ IterSmooth: è¿­ä»£å¹³æ»‘ç­–ç•¥                     â”‚
â”‚     â€¢ Vicinity: é‚»è¿‘çª—å£ç¼“å­˜æ›´æ–°                   â”‚
â”‚     â€¢ BlockDiffusion: å—æ‰©æ•£ï¼ˆä»… LLaDA2ï¼‰          â”‚
â”‚                                                     â”‚
â”‚  3. Decoder (å¹¶è¡Œè§£ç å™¨)                           â”‚
â”‚     â€¢ Threshold: åŸºäºç½®ä¿¡åº¦é˜ˆå€¼è§£ç                 â”‚
â”‚     â€¢ Hierarchy: å±‚æ¬¡åŒ–è§£ç ï¼ˆæ¯æ®µé€‰æœ€ä¼˜ï¼‰          â”‚
â”‚     â€¢ Credit: ä¿¡ç”¨åŠ æƒçš„é˜ˆå€¼è§£ç                    â”‚
â”‚                                                     â”‚
â”‚  4. KV-Cache Manager (ç¼“å­˜ç®¡ç†å™¨)                  â”‚
â”‚     â€¢ Prefix Cache: ä»…ç¼“å­˜å‰ç¼€                     â”‚
â”‚     â€¢ Dual Cache: åŒç¼“å­˜ä¼˜åŒ–                       â”‚
â”‚     â€¢ Vicinity Refresh: é‚»è¿‘çª—å£åˆ·æ–°ç­–ç•¥           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¸ä¼ ç»Ÿ LLM çš„åŒºåˆ«

| ç‰¹æ€§ | è‡ªå›å½’ LLM (å¦‚ GPT) | æ‰©æ•£ LLM (dInfer) |
|------|---------------------|-------------------|
| ç”Ÿæˆæ–¹å¼ | é€ä¸ª token ä¸²è¡Œç”Ÿæˆ | å¹¶è¡Œè¿­ä»£å»å™ªç”Ÿæˆ |
| è§£ç é€Ÿåº¦ | å—åºåˆ—é•¿åº¦çº¿æ€§é™åˆ¶ | é€šè¿‡å¹¶è¡Œè§£ç åŠ é€Ÿ |
| åˆå§‹çŠ¶æ€ | ä»å‰ç¼€å¼€å§‹ | å…¨éƒ¨ä¸º mask token |
| è¿­ä»£æ¬¡æ•° | O(N) æ¬¡å‰å‘ä¼ æ’­ | O(sqrt(N)) æ¬¡æ‰©æ•£è¿­ä»£ |
| KV-Cache | é€æ­¥ç´¯ç§¯ | éœ€è¦ç‰¹æ®Šç®¡ç†ç­–ç•¥ |

---

## ğŸ“– å‰ç½®çŸ¥è¯†

### å¿…å¤‡çŸ¥è¯† â­â­â­

1. **Python ç¼–ç¨‹**
   - é¢å‘å¯¹è±¡ç¼–ç¨‹ï¼ˆç±»ã€ç»§æ‰¿ã€å¤šæ€ï¼‰
   - è£…é¥°å™¨ï¼ˆ`@torch.no_grad()`, `@torch.compile()`ï¼‰
   - ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆ`with` è¯­å¥ï¼‰
   - å¤šè¿›ç¨‹/å¤šçº¿ç¨‹ç¼–ç¨‹

2. **PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶**
   - å¼ é‡æ“ä½œï¼ˆ`torch.Tensor`ï¼‰
   - è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶
   - æ¨¡å‹å®šä¹‰ä¸å‰å‘ä¼ æ’­
   - CUDA ç¼–ç¨‹åŸºç¡€ï¼ˆ`.to(device)`, `torch.cuda.set_device()`ï¼‰
   - åˆ†å¸ƒå¼è®­ç»ƒåŸºç¡€ï¼ˆ`torch.distributed`ï¼‰

3. **Transformer æ¶æ„**
   - è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰
   - å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attentionï¼‰
   - ä½ç½®ç¼–ç ï¼ˆPosition Encodingï¼‰
   - Feed-Forward Networks
   - **KV-Cache åŸç†**ï¼ˆé‡è¦ï¼ï¼‰

### æ¨èé¢„ä¹  â­â­

4. **æ‰©æ•£æ¨¡å‹åŸºç¡€** (éå¸¸é‡è¦!)
   - æ‰©æ•£è¿‡ç¨‹ï¼ˆå‰å‘åŠ å™ªè¿‡ç¨‹ï¼‰
   - å»å™ªè¿‡ç¨‹ï¼ˆåå‘ç”Ÿæˆè¿‡ç¨‹ï¼‰
   - å™ªå£°è°ƒåº¦ç­–ç•¥ï¼ˆNoise Scheduleï¼‰
   - æ¨èè®ºæ–‡:
     - DDPM (Denoising Diffusion Probabilistic Models)
     - DDIM (Denoising Diffusion Implicit Models)
     - **LLaDA è®ºæ–‡**: https://arxiv.org/abs/2510.08666

5. **æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰**
   - ä¸“å®¶è·¯ç”±æœºåˆ¶ï¼ˆRouterï¼‰
   - Top-K é€‰æ‹©ç­–ç•¥
   - è´Ÿè½½å‡è¡¡
   - Expert Parallel å¹¶è¡Œç­–ç•¥

6. **åˆ†å¸ƒå¼æ¨ç†**
   - Data Parallel (DP): æ•°æ®å¹¶è¡Œ
   - Tensor Parallel (TP): å¼ é‡å¹¶è¡Œ
   - Pipeline Parallel (PP): æµæ°´çº¿å¹¶è¡Œ
   - Expert Parallel (EP): ä¸“å®¶å¹¶è¡Œï¼ˆMoE ç‰¹æœ‰ï¼‰

### å¯é€‰ä½†æ¨è â­

7. **vLLM æ¡†æ¶**
   - PagedAttention æœºåˆ¶
   - è¿ç»­æ‰¹å¤„ç†ï¼ˆContinuous Batchingï¼‰
   - æ¨¡å‹å¹¶è¡Œç­–ç•¥
   - dInfer åŸºäº vLLM v0.10.2 æ„å»º

8. **HuggingFace ç”Ÿæ€**
   - Transformers åº“
   - Model Hub ä½¿ç”¨
   - `lm-eval-harness` è¯„ä¼°æ¡†æ¶

---

## ğŸ“ é¡¹ç›®ç»“æ„è¯¦è§£

```
dInfer/
â”‚
â”œâ”€â”€ python/dinfer/              # æ ¸å¿ƒä»£ç åº“
â”‚   â”œâ”€â”€ __init__.py            # å¯¹å¤– API å…¥å£
â”‚   â”‚   # å¯¼å‡º: ThresholdParallelDecoder, HierarchyDecoder, 
â”‚   â”‚   #       BlockWiseDiffusionLLM, KVCacheFactory ç­‰
â”‚   â”‚
â”‚   â”œâ”€â”€ model/                 # æ¨¡å‹å®ç°æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py                  # å¯¼å‡ºæ¨¡å‹ç±»
â”‚   â”‚   â”œâ”€â”€ modeling_llada.py            # LLaDA 8B æ¨¡å‹å®ç°
â”‚   â”‚   â”œâ”€â”€ modeling_fused_olmoe.py      # LLaDA-MoE 7B æ¨¡å‹ï¼ˆèåˆç‰ˆï¼‰
â”‚   â”‚   â”œâ”€â”€ modeling_llada2_moe.py       # LLaDA2 æ¨¡å‹ï¼ˆ16B-100Bï¼‰
â”‚   â”‚   â”œâ”€â”€ modeling_llada2_moe_sglang.py # LLaDA2 SGLang ç‰ˆæœ¬
â”‚   â”‚   â”œâ”€â”€ modeling_llada_fastdllm.py   # Fast-dLLM å®ç°ï¼ˆå¯¹æ¯”ç”¨ï¼‰
â”‚   â”‚   â”œâ”€â”€ configuration_llada.py       # LLaDA é…ç½®ç±»
â”‚   â”‚   â”œâ”€â”€ configuration_olmoe.py       # OLMoE é…ç½®ç±»
â”‚   â”‚   â”œâ”€â”€ configuration_llada2_moe.py  # LLaDA2 é…ç½®ç±»
â”‚   â”‚   â”œâ”€â”€ configuration_bailing_moe_v2.py # Bailing MoE é…ç½®
â”‚   â”‚   â””â”€â”€ tp_linear.py                 # å¼ é‡å¹¶è¡Œçº¿æ€§å±‚å®ç°
â”‚   â”‚
â”‚   â””â”€â”€ decoding/              # è§£ç é€»è¾‘æ¨¡å—ï¼ˆæ ¸å¿ƒï¼ï¼‰
â”‚       â”œâ”€â”€ __init__.py                   # å¯¼å‡ºè§£ç å™¨å’Œç”Ÿæˆç±»
â”‚       â”œâ”€â”€ utils.py                      # å·¥å…·ç±»ï¼ˆTokenArray, KVCache, è¿­ä»£å™¨ï¼‰
â”‚       â”œâ”€â”€ parallel_strategy.py          # å¹¶è¡Œè§£ç ç­–ç•¥å®ç°
â”‚       â”‚   # - ThresholdParallelDecoder: é˜ˆå€¼è§£ç 
â”‚       â”‚   # - CreditThresholdParallelDecoder: ä¿¡ç”¨è§£ç 
â”‚       â”‚   # - HierarchyDecoder: å±‚æ¬¡åŒ–è§£ç 
â”‚       â”‚
â”‚       â”œâ”€â”€ generate_uniform.py           # ä¸»æ¨ç†é€»è¾‘ï¼ˆæœ€é‡è¦ï¼ï¼‰
â”‚       â”‚   # - DiffusionLLM: åŸºç±»
â”‚       â”‚   # - BlockWiseDiffusionLLM: å—çº§æ‰©æ•£
â”‚       â”‚   # - IterSmoothDiffusionLLM: è¿­ä»£å¹³æ»‘
â”‚       â”‚   # - VicinityCacheDiffusionLLM: é‚»è¿‘ç¼“å­˜
â”‚       â”‚   # - BlockDiffusionLLM: å—æ‰©æ•£ï¼ˆLLaDA2ï¼‰
â”‚       â”‚
â”‚       â”œâ”€â”€ generate_fastdllm.py          # Fast-dLLM å®ç°
â”‚       â”œâ”€â”€ generate_hierarchy.py         # å±‚æ¬¡åŒ–ç”Ÿæˆ
â”‚       â”œâ”€â”€ generate_merge.py             # åˆå¹¶ç”Ÿæˆç­–ç•¥
â”‚       â”œâ”€â”€ generate_dist.py              # åˆ†å¸ƒå¼ç”Ÿæˆï¼ˆåºåˆ—å¹¶è¡Œï¼‰
â”‚       â”œâ”€â”€ generate_cache.py             # ç¼“å­˜ç®¡ç†å®ç°
â”‚       â”œâ”€â”€ diffusion_runner.py           # æ‰©æ•£è¿­ä»£æ‰§è¡Œå™¨
â”‚       â””â”€â”€ serving.py                    # åœ¨çº¿æœåŠ¡æ¥å£ï¼ˆå®éªŒæ€§ï¼‰
â”‚
â”œâ”€â”€ tests/                     # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_llada.py          # LLaDA æ¨¡å‹æµ‹è¯•
â”‚   â”œâ”€â”€ test_llada_moe.py      # LLaDA-MoE æ¨¡å‹æµ‹è¯•
â”‚   â”œâ”€â”€ test_bd.py             # å—æ‰©æ•£æµ‹è¯•
â”‚   â”œâ”€â”€ test_bd_serving.py     # å—æ‰©æ•£æœåŠ¡æµ‹è¯•
â”‚   â”œâ”€â”€ test_generate.py       # ç”Ÿæˆé€»è¾‘æµ‹è¯•
â”‚   â””â”€â”€ test_wo_model.py       # æ— æ¨¡å‹æµ‹è¯•ï¼ˆé€»è¾‘éªŒè¯ï¼‰
â”‚
â”œâ”€â”€ benchmarks/                # æ€§èƒ½åŸºå‡†æµ‹è¯•
â”‚   â”œâ”€â”€ benchmark.py           # å•æ ·æœ¬é€Ÿåº¦æµ‹è¯•
â”‚   â”œâ”€â”€ benchmark_dataset.py   # æ•°æ®é›†æ‰¹é‡æµ‹è¯•
â”‚   â”œâ”€â”€ benchmark_dataset_fastdllm.py  # Fast-dLLM å¯¹æ¯”
â”‚   â”œâ”€â”€ benchmark_dataset_sglang.py    # SGLang å¯¹æ¯”
â”‚   â””â”€â”€ benchmark_dataset_sorted.py    # æ’åºæ‰¹å¤„ç†æµ‹è¯•
â”‚
â”œâ”€â”€ evaluations/               # æ¨¡å‹è´¨é‡è¯„ä¼°
â”‚   â”œâ”€â”€ eval_dinfer.py         # è¯„ä¼°è„šæœ¬ï¼ˆåŸºäº lm-eval-harnessï¼‰
â”‚   â”œâ”€â”€ eval_guide.md          # è¯„ä¼°ä½¿ç”¨æŒ‡å—
â”‚   â”œâ”€â”€ eval_llada_moe.sh      # LLaDA-MoE è¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ tasks/                 # è‡ªå®šä¹‰è¯„ä¼°ä»»åŠ¡
â”‚       â”œâ”€â”€ gsm8k_llada/       # GSM8K æ•°å­¦æ¨ç†
â”‚       â””â”€â”€ mbpp_sanitized_llada/  # MBPP ä»£ç ç”Ÿæˆ
â”‚
â”œâ”€â”€ tools/                     # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ transfer.py            # æ¨¡å‹è½¬æ¢è„šæœ¬ï¼ˆè½¬ä¸º FusedMoEï¼‰
â”‚   â”œâ”€â”€ fuse_moe.py            # MoE èåˆé€»è¾‘
â”‚   â”œâ”€â”€ configuration_lladamoe.py  # LLaDA-MoE é…ç½®
â”‚   â””â”€â”€ modeling_fused_lladamoe.py # FusedMoE æ¨¡å‹å®ç°
â”‚
â”œâ”€â”€ assets/                    # èµ„æºæ–‡ä»¶ï¼ˆå›¾ç‰‡ã€logoï¼‰
â”œâ”€â”€ main.py                    # ç®€å•æ¨ç†ç¤ºä¾‹è„šæœ¬
â”œâ”€â”€ setup.py                   # å®‰è£…é…ç½®
â”œâ”€â”€ README.md                  # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â””â”€â”€ LICENSE                    # Apache 2.0 è®¸å¯è¯
```

---

## ğŸ’¡ æ ¸å¿ƒæ¦‚å¿µ

### 1. æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆdLLMï¼‰å·¥ä½œåŸç†

#### ä¼ ç»Ÿè‡ªå›å½’ç”Ÿæˆï¼ˆGPT é£æ ¼ï¼‰
```
è¾“å…¥: "What is the capital"
æ­¥éª¤: 
  1. é¢„æµ‹ -> "of"
  2. é¢„æµ‹ -> "France"
  3. é¢„æµ‹ -> "?"
  4. é¢„æµ‹ -> "\n"
  5. é¢„æµ‹ -> "Paris"
è¾“å‡º: "What is the capital of France?\nParis"
```

#### æ‰©æ•£æ¨¡å‹ç”Ÿæˆï¼ˆdInfer é£æ ¼ï¼‰
```
è¾“å…¥: "What is the capital"
åˆå§‹åŒ–: [MASK] [MASK] [MASK] [MASK] [MASK]

è¿­ä»£ 1: [of] [MASK] [MASK] [MASK] [MASK]      # é«˜ç½®ä¿¡åº¦ token å…ˆè§£ç 
è¿­ä»£ 2: [of] [France] [?] [MASK] [MASK]       # å¹¶è¡Œè§£ç å¤šä¸ª token
è¿­ä»£ 3: [of] [France] [?] [\n] [MASK]
è¿­ä»£ 4: [of] [France] [?] [\n] [Paris]        # æœ€ç»ˆå®Œæˆ

è¾“å‡º: "What is the capital of France?\nParis"
```

**æ ¸å¿ƒä¼˜åŠ¿**: åœ¨æ¯æ¬¡è¿­ä»£ä¸­å¯ä»¥**å¹¶è¡Œè§£ç å¤šä¸ª token**ï¼Œè€Œä¸æ˜¯é€ä¸ªç”Ÿæˆã€‚

### 2. å››å¤§ç»„ä»¶è¯¦è§£

#### ç»„ä»¶ 1: Modelï¼ˆæ¨¡å‹å±‚ï¼‰

**åŠŸèƒ½**: å®ç°æ‰©æ•£è¯­è¨€æ¨¡å‹çš„å‰å‘ä¼ æ’­é€»è¾‘

**æ”¯æŒçš„æ¨¡å‹**:
- **LLaDA**: 8B å‚æ•°ï¼ŒåŸºäº Llama æ¶æ„æ”¹é€ 
- **LLaDA-MoE**: 7B å‚æ•°ï¼Œä½¿ç”¨æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¶æ„
- **LLaDA2**: 16B-100B å‚æ•°ï¼Œæ”¯æŒå—æ‰©æ•£æœºåˆ¶

**å…³é”®æ–‡ä»¶**:
```python
# python/dinfer/model/modeling_llada.py
class LLaDAModelLM:
    def forward(self, input_ids, positions, kv_caches, ...):
        """
        å‰å‘ä¼ æ’­ï¼Œé¢„æµ‹æ¯ä¸ª MASK ä½ç½®çš„ token åˆ†å¸ƒ
        """
        # 1. Embedding
        # 2. Multi-layer Transformer
        # 3. Output logits
        return logits
```

#### ç»„ä»¶ 2: Diffusion Iteration Managerï¼ˆè¿­ä»£ç®¡ç†å™¨ï¼‰

**åŠŸèƒ½**: æ§åˆ¶æ‰©æ•£è¿­ä»£çš„æ‰§è¡Œæµç¨‹å’Œä¼˜åŒ–ç­–ç•¥

**ä¸»è¦ç­–ç•¥**:
- **BlockWise**: å°†ç”Ÿæˆåºåˆ—åˆ†æˆå¤šä¸ªå—ï¼Œé€å—ç”Ÿæˆ
- **IterSmooth**: è¿­ä»£å¹³æ»‘ï¼Œé€æ­¥é™ä½é˜ˆå€¼ä»¥å¹³æ»‘ç”Ÿæˆ
- **Vicinity Cache**: é‚»è¿‘çª—å£ç¼“å­˜åˆ·æ–°ç­–ç•¥
- **BlockDiffusion**: LLaDA2 çš„å—çº§æ‰©æ•£ï¼ˆå‡å°‘è®¡ç®—å¼€é”€ï¼‰

**å…³é”®ç±»**:
```python
# python/dinfer/decoding/generate_uniform.py
class BlockWiseDiffusionLLM:
    def generate(self, prompt, gen_length, block_length):
        """
        å—çº§æ‰©æ•£ç”Ÿæˆ
        1. åˆå§‹åŒ–: åˆ›å»ºå…¨ MASK åºåˆ—
        2. è¿­ä»£: å¯¹æ¯ä¸ªå—æ‰§è¡Œæ‰©æ•£è¿­ä»£
        3. è§£ç : ä½¿ç”¨ Decoder é€‰æ‹©é«˜ç½®ä¿¡åº¦ token
        4. æ›´æ–°: æ›´æ–° KV-Cache
        """
```

#### ç»„ä»¶ 3: Decoderï¼ˆå¹¶è¡Œè§£ç å™¨ï¼‰

**åŠŸèƒ½**: åœ¨æ¯æ¬¡æ‰©æ•£è¿­ä»£ä¸­ï¼Œå†³å®šå“ªäº› MASK token åº”è¯¥è¢«è§£ç 

**ä¸‰ç§è§£ç ç­–ç•¥**:

1. **Threshold Decoderï¼ˆé˜ˆå€¼è§£ç ï¼‰**
```python
class ThresholdParallelDecoder:
    def decode(self, logits, mask_index):
        """
        å¦‚æœ token çš„é¢„æµ‹ç½®ä¿¡åº¦ > thresholdï¼Œåˆ™è§£ç è¯¥ token
        
        ä¾‹å¦‚: threshold = 0.9
        - "of" ç½®ä¿¡åº¦ 0.95 -> è§£ç  âœ“
        - "France" ç½®ä¿¡åº¦ 0.87 -> ä¿æŒ MASK âœ—
        """
```

2. **Hierarchy Decoderï¼ˆå±‚æ¬¡è§£ç ï¼‰**
```python
class HierarchyDecoder:
    def decode(self, logits, mask_index):
        """
        å°† MASK åºåˆ—åˆ†æ®µï¼Œæ¯æ®µé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ token è§£ç 
        
        ä¼˜åŠ¿: ä¿è¯æ¯æ¬¡è¿­ä»£éƒ½æœ‰è¿›å±•ï¼Œé¿å…å¡ä½
        """
```

3. **Credit Decoderï¼ˆä¿¡ç”¨è§£ç ï¼‰**
```python
class CreditThresholdParallelDecoder:
    def decode(self, logits, mask_index, history):
        """
        åŸºäºå†å²ç½®ä¿¡åº¦åŠ æƒï¼Œç»™"è¡¨ç°å¥½"çš„ä½ç½®æ›´é«˜çš„ä¿¡ç”¨
        """
```

#### ç»„ä»¶ 4: KV-Cache Managerï¼ˆç¼“å­˜ç®¡ç†å™¨ï¼‰

**åŠŸèƒ½**: é«˜æ•ˆç®¡ç† Transformer çš„ Key-Value ç¼“å­˜

**ä¸‰ç§ç¼“å­˜ç­–ç•¥**:

1. **Prefix Cacheï¼ˆå‰ç¼€ç¼“å­˜ï¼‰**
   - åªç¼“å­˜è¾“å…¥å‰ç¼€çš„ KV
   - é€‚ç”¨äºå›ºå®šå‰ç¼€çš„åœºæ™¯

2. **Dual Cacheï¼ˆåŒç¼“å­˜ï¼‰**
   - åŒæ—¶ç»´æŠ¤ä¸¤ä¸ªç¼“å­˜ï¼šå½“å‰å—ç¼“å­˜ + å†å²ç¼“å­˜
   - åœ¨å—é—´åˆ‡æ¢æ—¶åˆå¹¶

3. **Vicinity Refreshï¼ˆé‚»è¿‘åˆ·æ–°ï¼‰**
   - å®šä¹‰ä¸€ä¸ªçª—å£ï¼Œåªåˆ·æ–°çª—å£å†…çš„ KV-Cache
   - å‡å°‘ç¼“å­˜æ›´æ–°å¼€é”€

**å…³é”®ç±»**:
```python
# python/dinfer/decoding/utils.py
class DiffusionKVCacheManager:
    def update_cache(self, block_loc, new_kv):
        """
        æ ¹æ®ç­–ç•¥æ›´æ–° KV-Cache
        """
```

### 3. å·¥ä½œæµç¨‹ç¤ºä¾‹

```
ç”¨æˆ·è¾“å…¥ prompt
    â†“
[åˆå§‹åŒ–é˜¶æ®µ]
â€¢ TokenArray: åˆ›å»º [prompt] + [MASK * gen_length]
â€¢ KVCache: åˆå§‹åŒ–ç¼“å­˜
    â†“
[è¿­ä»£é˜¶æ®µ - ç¬¬ä¸€ä¸ªå—]
å¾ªç¯:
  1. Model.forward(input_ids, kv_cache)
      â†“ è¾“å‡º logits
  2. Decoder.decode(logits, mask_index)
      â†“ é€‰æ‹©é«˜ç½®ä¿¡åº¦ token
  3. æ›´æ–° input_ids (MASK -> decoded token)
  4. KVCacheManager.update(...)
      â†“ æ›´æ–°ç¼“å­˜
  ç›´åˆ°: å½“å‰å—æ‰€æœ‰ MASK éƒ½è¢«è§£ç 
    â†“
[è¿­ä»£é˜¶æ®µ - ç¬¬äºŒä¸ªå—]
ï¼ˆé‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼‰
    â†“
[è¾“å‡ºé˜¶æ®µ]
â€¢ ç§»é™¤ EOS åçš„æ‰€æœ‰ token
â€¢ è¿”å›ç”Ÿæˆç»“æœ
```

---

## ğŸš€ å­¦ä¹ è·¯çº¿

### ğŸ“… é˜¶æ®µ 0: ç¯å¢ƒå‡†å¤‡ï¼ˆ0.5å¤©ï¼‰

#### ç›®æ ‡
- æ­å»ºå¼€å‘ç¯å¢ƒ
- æˆåŠŸè¿è¡Œç¬¬ä¸€ä¸ªæ¨ç†ç¤ºä¾‹

#### æ­¥éª¤

**1. å®‰è£… dInfer**
```bash
# å…‹éš†ä»“åº“
git clone https://github.com/inclusionAI/dInfer.git
cd dInfer

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# å®‰è£…ä¾èµ–
pip install .

# éªŒè¯å®‰è£…
python -c "import dinfer; print(dinfer.__version__)"
```

**2. ä¸‹è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼Œç”¨äºæµ‹è¯•ï¼‰**
```bash
# å®‰è£…ä¸‹è½½å·¥å…·
pip install -U huggingface_hub hf_transfer
export HF_HUB_ENABLE_HF_TRANSFER=1

# ä¸‹è½½ LLaDA-MoE æ¨¡å‹ï¼ˆéœ€è¦å…ˆè½¬æ¢ä¸º FusedMoEï¼‰
huggingface-cli download inclusionAI/LLaDA-MoE-7B-A1B-Instruct \
  --local-dir ./models/LLaDA-MoE-7B-A1B-Instruct

# è½¬æ¢ä¸º FusedMoE
python -m tools.transfer \
  --input ./models/LLaDA-MoE-7B-A1B-Instruct \
  --output ./models/LLaDA-MoE-7B-A1B-Instruct-fused
```

**3. è¿è¡Œç¬¬ä¸€ä¸ªæ¨ç†**
```bash
# ä½¿ç”¨ main.py ç¤ºä¾‹è„šæœ¬
python main.py
```

**é¢„æœŸè¾“å‡º**:
```
[1/5] åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ...
ä½¿ç”¨è®¾å¤‡: cuda:0
[2/5] åŠ è½½æ¨¡å‹: /path/to/model
åˆ†è¯å™¨åŠ è½½å®Œæˆ
æ¨¡å‹åŠ è½½å®Œæˆ (bfloat16)
[3/5] åˆ›å»ºæ‰©æ•£è¯­è¨€æ¨¡å‹æ¨ç†å™¨...
è§£ç å™¨: ThresholdParallelDecoder (threshold=0.9)
KV-Cache: Dual Cache
[4/5] è¿è¡Œæ¨ç†æµ‹è¯• (gen_length=128, block_length=32)...
================================================================================

ã€æµ‹è¯• 1/3ã€‘
æç¤ºè¯: Lily can run 12 kilometers per hour...
--------------------------------------------------------------------------------
ç”Ÿæˆç»“æœ:
Lily can run 12 * 4 = 48 kilometers in 4 hours...
================================================================================
```

---

### ğŸ“… é˜¶æ®µ 1: åŸºç¡€ç†è§£ï¼ˆ1-2å¤©ï¼‰

#### ç›®æ ‡
- ç†è§£æ‰©æ•£è¯­è¨€æ¨¡å‹çš„åŸºæœ¬åŸç†
- æŒæ¡ dInfer çš„æ•´ä½“æ¶æ„
- ç†è§£å››å¤§æ ¸å¿ƒç»„ä»¶çš„ä½œç”¨

#### å­¦ä¹ ææ–™

**1. é˜…è¯»æ–‡æ¡£**
```bash
# é¡¹ç›® README
cat README.md

# è¯„ä¼°æŒ‡å—
cat evaluations/eval_guide.md
```

**2. é˜…è¯»è®ºæ–‡ï¼ˆå¼ºçƒˆæ¨èï¼‰**
- **dInfer æŠ€æœ¯æŠ¥å‘Š**: https://arxiv.org/abs/2510.08666
- **LLaDA è®ºæ–‡**: æŸ¥çœ‹ HuggingFace æ¨¡å‹å¡ç‰‡

**3. ç†è§£æ ¸å¿ƒæ¦‚å¿µ**
- ä»€ä¹ˆæ˜¯æ‰©æ•£æ¨¡å‹ï¼Ÿ
- æ‰©æ•£è¯­è¨€æ¨¡å‹ä¸ä¼ ç»Ÿ LLM çš„åŒºåˆ«
- å¹¶è¡Œè§£ç å¦‚ä½•å·¥ä½œï¼Ÿ

#### å®è·µä»»åŠ¡

**ä»»åŠ¡ 1: è¿è¡Œç®€å•æ¨ç†**
```bash
# ä½¿ç”¨ benchmark.py æµ‹è¯•å•æ ·æœ¬æ¨ç†
python benchmarks/benchmark.py \
  --model_name your_model_path \
  --model_type llada_moe \
  --gen_len 512 \
  --block_length 32 \
  --gpu 0 \
  --parallel_decoding threshold \
  --threshold 0.9
```

**ä»»åŠ¡ 2: å¯¹æ¯”ä¸åŒè§£ç ç­–ç•¥**
```bash
# Threshold è§£ç 
python benchmarks/benchmark.py --parallel_decoding threshold --threshold 0.9

# Hierarchy è§£ç 
python benchmarks/benchmark.py --parallel_decoding hierarchy --threshold 0.9 --low_threshold 0.5
```

è§‚å¯Ÿè¾“å‡ºï¼Œç†è§£ä¸åŒç­–ç•¥çš„å·®å¼‚ã€‚

**ä»»åŠ¡ 3: é˜…è¯»å…¥å£ä»£ç **
```bash
# æ‰“å¼€æ ¸å¿ƒå…¥å£æ–‡ä»¶
vim python/dinfer/__init__.py
vim main.py
```

ç†è§£ API è®¾è®¡ï¼š
```python
from dinfer import (
    BlockWiseDiffusionLLM,      # æ¨ç†å¼•æ“
    ThresholdParallelDecoder,   # è§£ç å™¨
    KVCacheFactory,             # ç¼“å­˜å·¥å‚
    BlockIteratorFactory,       # è¿­ä»£å™¨å·¥å‚
)
```

---

### ğŸ“… é˜¶æ®µ 2: æ·±å…¥è§£ç é€»è¾‘ï¼ˆ2-3å¤©ï¼‰

#### ç›®æ ‡
- ç†è§£æ‰©æ•£è¿­ä»£çš„æ‰§è¡Œæµç¨‹
- æŒæ¡å¹¶è¡Œè§£ç ç­–ç•¥çš„å®ç°
- ç†è§£ KV-Cache ç®¡ç†æœºåˆ¶

#### å­¦ä¹ è·¯å¾„

**ç¬¬ 1 å¤©: å·¥å…·ç±»å’Œæ•°æ®ç»“æ„**

é˜…è¯»æ–‡ä»¶: `python/dinfer/decoding/utils.py`

**å…³é”®ç±»**:
```python
# 1. TokenArray: ç®¡ç†ç”Ÿæˆåºåˆ—
class TokenArray:
    """
    å­˜å‚¨ prompt + ç”Ÿæˆçš„ tokenï¼ˆåŒ…æ‹¬ MASKï¼‰
    """
    def __init__(self, prompt, gen_length, mask_id, eos_id, device)
    def get_generated_tokens(self)
    def select_seqs(self, idx)

# 2. BlockIterator: è¿­ä»£å—
class BlockIterator:
    """
    éå†ç”Ÿæˆåºåˆ—ä¸­çš„æ¯ä¸ªå—
    """
    def __iter__(self)
    def __next__(self)  # è¿”å› (block, block_loc)

# 3. KVCacheFactory: åˆ›å»ºç¼“å­˜
class KVCacheFactory:
    """
    æ ¹æ®ç­–ç•¥åˆ›å»ºä¸åŒçš„ KV-Cache
    """
    def __call__(self, strategy):
        if strategy == "prefix":
            return PrefixKVCache(...)
        elif strategy == "dual":
            return DualKVCache(...)
```

**å®è·µ**: å†™ä¸€ä¸ªç®€å•çš„æµ‹è¯•è„šæœ¬
```python
import torch
from dinfer.decoding.utils import TokenArray, BlockIterator

# åˆ›å»º TokenArray
prompt = torch.tensor([[1, 2, 3, 4, 5]])
token_array = TokenArray(prompt, gen_length=16, mask_id=999, eos_id=888, device='cuda:0')

# éå†å—
iterator = BlockIterator(token_array, block_length=4)
for block, block_loc in iterator:
    print(f"Block: {block}, Location: {block_loc.start}-{block_loc.end}")
```

**ç¬¬ 2 å¤©: å¹¶è¡Œè§£ç ç­–ç•¥**

é˜…è¯»æ–‡ä»¶: `python/dinfer/decoding/parallel_strategy.py`

**å…³é”®å‡½æ•°**:
```python
# 1. get_transfer_index_hierarchy_fast_v2
def get_transfer_index_hierarchy_fast_v2(
    logits,         # æ¨¡å‹è¾“å‡ºçš„ logits
    temperature,    # Gumbel å™ªå£°æ¸©åº¦
    remasking,      # é‡æ–° mask ç­–ç•¥
    mask_index,     # å½“å‰å“ªäº›ä½ç½®æ˜¯ MASK
    x,              # å½“å‰åºåˆ—
    num_transfer_tokens,  # æ¯æ¬¡è§£ç å¤šå°‘ token
    mask_id,
    threshold=None,
    low_threshold=None
):
    """
    æ ¸å¿ƒè§£ç é€»è¾‘:
    1. æ·»åŠ  Gumbel å™ªå£°ï¼ˆç”¨äºé‡‡æ ·ï¼‰
    2. è®¡ç®—æ¯ä¸ªä½ç½®çš„ç½®ä¿¡åº¦
    3. æ ¹æ®é˜ˆå€¼æˆ–å±‚æ¬¡ç­–ç•¥é€‰æ‹©è¦è§£ç çš„ token
    4. è¿”å›è§£ç åçš„ token å’Œ transfer_index
    """
```

**å®è·µ**: å•å…ƒæµ‹è¯•
```bash
# è¿è¡Œè§£ç ç­–ç•¥æµ‹è¯•
python tests/test_wo_model.py
```

åˆ†æè¾“å‡ºï¼Œç†è§£ï¼š
- ç½®ä¿¡åº¦å¦‚ä½•è®¡ç®—ï¼Ÿ
- é˜ˆå€¼å¦‚ä½•å½±å“è§£ç é€Ÿåº¦ï¼Ÿ
- å±‚æ¬¡è§£ç å¦‚ä½•ä¿è¯æ¯æ¬¡è¿­ä»£éƒ½æœ‰è¿›å±•ï¼Ÿ

**ç¬¬ 3 å¤©: ä¸»æ¨ç†é€»è¾‘**

é˜…è¯»æ–‡ä»¶: `python/dinfer/decoding/generate_uniform.py`ï¼ˆæœ€é‡è¦ï¼ï¼‰

**æ ¸å¿ƒç±»ç»“æ„**:
```python
# åŸºç±»
class DiffusionLLM:
    def generate(self, prompt, gen_length, block_length):
        """åŸºç±»ï¼Œå®šä¹‰æ¥å£"""
        raise NotImplementedError

# å—çº§æ‰©æ•£
class BlockWiseDiffusionLLM(DiffusionLLM):
    def __init__(self, model, decoder, iterator_factory, cache_factory, ...):
        self.model = model           # æ‰©æ•£è¯­è¨€æ¨¡å‹
        self.decoder = decoder       # å¹¶è¡Œè§£ç å™¨
        self.cache_factory = cache_factory  # KV-Cache å·¥å‚
        
    def generate(self, prompt, gen_length, block_length):
        # 1. åˆå§‹åŒ– TokenArray
        x = TokenArray(prompt, gen_length, mask_id, eos_id, device)
        
        # 2. åˆå§‹åŒ– KV-Cache
        kv_cache = self.cache_factory.create(...)
        
        # 3. éå†æ¯ä¸ªå—
        for block, block_loc in iterator:
            # 4. æ‰§è¡Œæ‰©æ•£è¿­ä»£ï¼Œç›´åˆ°å—å†…æ‰€æœ‰ MASK è¢«è§£ç 
            while (block == mask_id).sum() > 0:
                # a. å‰å‘ä¼ æ’­
                logits = self.model.forward(x.data, kv_cache=kv_cache)
                
                # b. è§£ç ï¼ˆé€‰æ‹©é«˜ç½®ä¿¡åº¦ tokenï¼‰
                x0, transfer_index = self.decoder.decode(logits, mask_index)
                
                # c. æ›´æ–°åºåˆ—
                x[block_loc.start:block_loc.end] = torch.where(
                    transfer_index, x0, x[block_loc.start:block_loc.end]
                )
                
                # d. æ›´æ–° KV-Cache
                kv_cache.update(block_loc, ...)
        
        # 5. è¿”å›ç”Ÿæˆç»“æœ
        return x.get_generated_tokens()
```

**å®è·µ**: æ·»åŠ æ—¥å¿—ï¼Œè·Ÿè¸ªæ‰§è¡Œæµç¨‹
```python
# ä¿®æ”¹ generate_uniform.pyï¼Œæ·»åŠ æ‰“å°è¯­å¥
def generate(self, prompt, gen_length, block_length):
    print(f"[Init] Prompt length: {prompt.shape[1]}, Gen length: {gen_length}")
    
    for block_id, (block, block_loc) in enumerate(iterator):
        print(f"[Block {block_id}] Processing {block_loc.start}-{block_loc.end}")
        iter_count = 0
        
        while (block == mask_id).sum() > 0:
            iter_count += 1
            mask_count = (block == mask_id).sum().item()
            print(f"  [Iter {iter_count}] Remaining MASK: {mask_count}")
            
            # ... æ‰§è¡Œè§£ç  ...
```

---

### ğŸ“… é˜¶æ®µ 3: æ¨¡å‹å®ç°ï¼ˆ2-3å¤©ï¼‰

#### ç›®æ ‡
- ç†è§£æ‰©æ•£è¯­è¨€æ¨¡å‹çš„æ¶æ„
- æŒæ¡å¼ é‡å¹¶è¡Œï¼ˆTPï¼‰å’Œä¸“å®¶å¹¶è¡Œï¼ˆEPï¼‰çš„å®ç°
- ç†è§£ MoE æ¶æ„çš„ç‰¹ç‚¹

#### å­¦ä¹ è·¯å¾„

**ç¬¬ 1 å¤©: LLaDA åŸºç¡€æ¨¡å‹**

é˜…è¯»æ–‡ä»¶: `python/dinfer/model/modeling_llada.py`

**æ ¸å¿ƒç±»**:
```python
class LLaDAModelLM(PreTrainedModel):
    """
    LLaDA æ¨¡å‹å®ç°ï¼ŒåŸºäº Llama æ¶æ„
    """
    def __init__(self, config):
        self.model = LLaDAModel(config)
        self.lm_head = nn.Linear(hidden_size, vocab_size)
    
    def forward(self, input_ids, positions, kv_caches, ...):
        """
        å‰å‘ä¼ æ’­
        1. Token Embedding
        2. å¤šå±‚ Transformer Block
        3. Output Projection
        """
        hidden_states = self.model(input_ids, positions, kv_caches)
        logits = self.lm_head(hidden_states)
        return logits
```

**å…³é”®ç»„ä»¶**:
- `LLaDAAttention`: è‡ªæ³¨æ„åŠ›å±‚
- `LLaDAMLP`: å‰é¦ˆç½‘ç»œ
- `LLaDABlock`: Transformer å—

**ç¬¬ 2 å¤©: LLaDA-MoE æ¨¡å‹**

é˜…è¯»æ–‡ä»¶: `python/dinfer/model/modeling_fused_olmoe.py`

**MoE æ ¸å¿ƒ**:
```python
class OlmoeMoE(nn.Module):
    """
    æ··åˆä¸“å®¶å±‚
    """
    def __init__(self, config):
        self.num_experts = config.num_experts  # ä¸“å®¶æ•°é‡
        self.top_k = config.num_experts_per_tok  # æ¯ä¸ª token é€‰æ‹©çš„ä¸“å®¶æ•°
        self.gate = nn.Linear(hidden_size, num_experts)  # è·¯ç”±å™¨
        self.experts = nn.ModuleList([
            OlmoeMLP(config) for _ in range(num_experts)
        ])
    
    def forward(self, hidden_states):
        # 1. è·¯ç”±ï¼šé€‰æ‹© top-k ä¸“å®¶
        router_logits = self.gate(hidden_states)
        routing_weights, selected_experts = torch.topk(router_logits, self.top_k)
        
        # 2. ä¸“å®¶è®¡ç®—
        expert_outputs = []
        for expert_idx in selected_experts:
            expert_outputs.append(self.experts[expert_idx](hidden_states))
        
        # 3. åŠ æƒåˆå¹¶
        output = sum(w * o for w, o in zip(routing_weights, expert_outputs))
        return output
```

**å…³é”®æ¦‚å¿µ**:
- **Expert Parallel**: ä¸åŒ GPU è´Ÿè´£ä¸åŒä¸“å®¶
- **Load Balancing**: ç¡®ä¿ä¸“å®¶è´Ÿè½½å‡è¡¡
- **Fused MoE**: èåˆå¤šä¸ªä¸“å®¶çš„æƒé‡çŸ©é˜µï¼Œæé«˜æ•ˆç‡

**ç¬¬ 3 å¤©: LLaDA2 å—æ‰©æ•£æ¨¡å‹**

é˜…è¯»æ–‡ä»¶: `python/dinfer/model/modeling_llada2_moe.py`

**å—æ‰©æ•£ç‰¹ç‚¹**:
```python
class LLaDA2MoeModelLM:
    """
    LLaDA2 æ”¯æŒå—æ‰©æ•£æœºåˆ¶
    - å‡å°‘è®¡ç®—å¼€é”€ï¼šä¸éœ€è¦æ¯æ¬¡è¿­ä»£éƒ½è®¡ç®—æ•´ä¸ªåºåˆ—
    - ä½¿ç”¨ Attention Mask ä¼˜åŒ–
    """
    def forward(self, input_ids, attention_mask=None, ...):
        # å—æ‰©æ•£ï¼šåªè®¡ç®—å½“å‰å—ï¼Œä¸è®¡ç®—åç»­ MASK å—
        if use_block_diffusion:
            # ä½¿ç”¨ attention_mask å±è”½åç»­å—
            attention_mask = create_block_mask(...)
        
        return super().forward(input_ids, attention_mask=attention_mask)
```

**å®è·µ**: å¯¹æ¯”æ¨¡å‹å¤§å°å’Œé€Ÿåº¦
```bash
# LLaDA 8B
python benchmarks/benchmark.py --model_type llada --model_name GSAI-ML/LLaDA-8B-Instruct

# LLaDA-MoE 7B
python benchmarks/benchmark.py --model_type llada_moe --model_name inclusionAI/LLaDA-MoE-7B-A1B-Instruct-fused

# LLaDA2 16B
python benchmarks/benchmark.py --model_type llada2 --model_name inclusionAI/LLaDA2.0-mini-preview --use_bd
```

---

### ğŸ“… é˜¶æ®µ 4: é«˜çº§ä¼˜åŒ–ï¼ˆ2-3å¤©ï¼‰

#### ç›®æ ‡
- ç†è§£ç³»ç»Ÿçº§ä¼˜åŒ–æŠ€æœ¯
- æŒæ¡å¼ é‡å¹¶è¡Œå’Œä¸“å®¶å¹¶è¡Œ
- å­¦ä¹  PyTorch ç¼–è¯‘å’Œ CUDA Graphs

#### å­¦ä¹ å†…å®¹

**1. å¼ é‡å¹¶è¡Œï¼ˆTensor Parallelï¼‰**

é˜…è¯»æ–‡ä»¶: `python/dinfer/model/tp_linear.py`

```python
class TPLinear(nn.Module):
    """
    å¼ é‡å¹¶è¡Œçº¿æ€§å±‚
    å°†æƒé‡çŸ©é˜µæŒ‰åˆ—æˆ–è¡Œåˆ‡åˆ†åˆ°å¤šä¸ª GPU
    """
    def __init__(self, in_features, out_features, world_size, rank, dim='column'):
        self.world_size = world_size
        self.rank = rank
        
        if dim == 'column':
            # åˆ—åˆ‡åˆ†ï¼šæ¯ä¸ª GPU è´Ÿè´£éƒ¨åˆ†è¾“å‡ºç»´åº¦
            self.weight = nn.Parameter(torch.randn(out_features // world_size, in_features))
        else:
            # è¡Œåˆ‡åˆ†ï¼šæ¯ä¸ª GPU è´Ÿè´£éƒ¨åˆ†è¾“å…¥ç»´åº¦
            self.weight = nn.Parameter(torch.randn(out_features, in_features // world_size))
    
    def forward(self, x):
        # åˆ†å¸ƒå¼çŸ©é˜µä¹˜æ³•
        local_output = F.linear(x, self.weight)
        
        # All-reduce æˆ– All-gather åŒæ­¥ç»“æœ
        if self.dim == 'column':
            output = dist.all_reduce(local_output)
        else:
            output = dist.all_gather(local_output)
        
        return output
```

**å®è·µ**: å¯ç”¨ TP
```bash
# å• GPU
python benchmarks/benchmark.py --gpu 0

# 4-way TP
python benchmarks/benchmark.py --gpu 0,1,2,3 --use_tp
```

**2. PyTorch ç¼–è¯‘ä¼˜åŒ–**

```python
# åœ¨ benchmark.py ä¸­å¯ç”¨ç¼–è¯‘
model.forward = torch.compile(
    model.forward, 
    mode='reduce-overhead',  # å‡å°‘å¼€é”€
    fullgraph=False,         # å…è®¸ graph breaks
    dynamic=True             # æ”¯æŒåŠ¨æ€å½¢çŠ¶
)
```

**æ•ˆæœ**: å‡å°‘ Python å¼€é”€ï¼Œèåˆ CUDA æ ¸å‡½æ•°

**3. CUDA Graphs**

CUDA Graphs å¯ä»¥"è®°å½•"ä¸€ç³»åˆ— CUDA æ“ä½œï¼Œç„¶åé‡æ”¾ï¼Œå‡å°‘ CPU-GPU é€šä¿¡å¼€é”€ã€‚

```python
# ä½¿ç”¨ CUDA Graphsï¼ˆåœ¨ vLLM ä¸­è‡ªåŠ¨å¯ç”¨ï¼‰
with torch.cuda.graph():
    output = model(input_ids)
```

**4. Loop Unrollingï¼ˆå¾ªç¯å±•å¼€ï¼‰**

åœ¨ `generate_uniform.py` ä¸­çš„ä¼˜åŒ–ï¼š
```python
# å±•å¼€å¾ªç¯ï¼Œå‡å°‘ Python å¾ªç¯å¼€é”€
while (block == mask_id).sum() > 0:
    unroll_k = min((block == mask_id).sum() // expected_tpf, maximum_unroll)
    for unroll_i in range(unroll_k):
        # æ‰§è¡Œå¤šæ¬¡è¿­ä»£è€Œä¸æ£€æŸ¥æ¡ä»¶
        self.diff_iteration.forward(model, decoder, ...)
```

**å®è·µ**: å¯¹æ¯”ä¼˜åŒ–æ•ˆæœ
```bash
# ä¸ä½¿ç”¨ç¼–è¯‘
python benchmarks/benchmark.py --no_compile

# ä½¿ç”¨ç¼–è¯‘
python benchmarks/benchmark.py --use_compile

# è§‚å¯Ÿ TPS æå‡
```

---

### ğŸ“… é˜¶æ®µ 5: è¯„ä¼°ä¸å®éªŒï¼ˆ2-3å¤©ï¼‰

#### ç›®æ ‡
- å­¦ä¼šä½¿ç”¨è¯„ä¼°æ¡†æ¶
- åœ¨æ ‡å‡† benchmark ä¸Šæµ‹è¯•æ¨¡å‹
- åˆ†ææ€§èƒ½å’Œè´¨é‡çš„æƒè¡¡

#### å®è·µä»»åŠ¡

**ä»»åŠ¡ 1: è¿è¡Œæ ‡å‡† benchmark**

```bash
cd evaluations

# GSM8K æ•°å­¦æ¨ç†
python eval_dinfer.py \
  --tasks gsm8k_llada_moe \
  --model dInfer_eval \
  --model_args model_path=your_model,gen_length=1024,block_length=64,threshold=0.8 \
  --output_path runs/gsm8k

# MBPP ä»£ç ç”Ÿæˆ
python eval_dinfer.py \
  --tasks mbpp_sanitized_llada_moe \
  --confirm_run_unsafe_code \
  --model_args model_path=your_model,gen_length=1024,block_length=64,threshold=0.8 \
  --output_path runs/mbpp
```

**ä»»åŠ¡ 2: å‚æ•°è°ƒä¼˜å®éªŒ**

åˆ›å»ºå®éªŒè„šæœ¬ `experiments/param_sweep.sh`:
```bash
#!/bin/bash

# æµ‹è¯•ä¸åŒé˜ˆå€¼
for threshold in 0.7 0.8 0.9 0.95; do
  python benchmarks/benchmark_dataset.py \
    --threshold $threshold \
    --output_dir runs/threshold_$threshold
done

# æµ‹è¯•ä¸åŒå—å¤§å°
for block_length in 16 32 64 128; do
  python benchmarks/benchmark_dataset.py \
    --block_length $block_length \
    --output_dir runs/block_$block_length
done


# æµ‹è¯•ä¸åŒç¼“å­˜ç­–ç•¥
for cache in prefix dual vicinity; do
  python benchmarks/benchmark_dataset.py \
    --cache $cache \
    --output_dir runs/cache_$cache
done
```

**ä»»åŠ¡ 3: åˆ†æç»“æœ**

```python
import json
import pandas as pd
import matplotlib.pyplot as plt

# åŠ è½½å®éªŒç»“æœ
results = []
for threshold in [0.7, 0.8, 0.9, 0.95]:
    with open(f'runs/threshold_{threshold}/metrics.json') as f:
        data = json.load(f)
        results.append({
            'threshold': threshold,
            'tps': data['tokens_per_second'],
            'accuracy': data['accuracy']
        })

df = pd.DataFrame(results)

# ç»˜åˆ¶é€Ÿåº¦-è´¨é‡æ›²çº¿
plt.plot(df['tps'], df['accuracy'], 'o-')
plt.xlabel('Tokens Per Second')
plt.ylabel('Accuracy')
plt.title('Speed-Quality Tradeoff')
plt.savefig('speed_quality.png')
```

---

## ğŸ› ï¸ å®è·µé¡¹ç›®

### é¡¹ç›® 1: è‡ªå®šä¹‰è§£ç ç­–ç•¥ â­â­

**ç›®æ ‡**: å®ç°ä¸€ä¸ªæ–°çš„è§£ç ç­–ç•¥

**ä»»åŠ¡**:
1. åœ¨ `parallel_strategy.py` ä¸­æ·»åŠ æ–°ç±» `AdaptiveDecoder`
2. ç­–ç•¥ï¼šæ ¹æ®å½“å‰è¿­ä»£æ¬¡æ•°åŠ¨æ€è°ƒæ•´é˜ˆå€¼
   - æ—©æœŸè¿­ä»£ï¼šé«˜é˜ˆå€¼ï¼ˆ0.95ï¼‰ï¼Œåªè§£ç æœ€ç¡®å®šçš„ token
   - åæœŸè¿­ä»£ï¼šä½é˜ˆå€¼ï¼ˆ0.7ï¼‰ï¼ŒåŠ é€Ÿè§£ç 

**å®ç°æ¡†æ¶**:
```python
class AdaptiveDecoder:
    def __init__(self, initial_threshold=0.95, final_threshold=0.7, mask_id, eos_id):
        self.initial_threshold = initial_threshold
        self.final_threshold = final_threshold
        self.mask_id = mask_id
        self.eos_id = eos_id
        self.iter_count = 0
        self.total_iters = 10  # é¢„ä¼°æ€»è¿­ä»£æ¬¡æ•°
    
    def decode(self, logits, mask_index, x):
        self.iter_count += 1
        
        # çº¿æ€§è¡°å‡é˜ˆå€¼
        progress = self.iter_count / self.total_iters
        current_threshold = (
            self.initial_threshold * (1 - progress) + 
            self.final_threshold * progress
        )
        
        # ä½¿ç”¨å½“å‰é˜ˆå€¼è§£ç 
        # TODO: å®ç°è§£ç é€»è¾‘
        
        return x0, transfer_index
```

**æµ‹è¯•**:
```bash
python benchmarks/benchmark.py \
  --parallel_decoding adaptive \
  --output_dir runs/adaptive
```

---

### é¡¹ç›® 2: å¯è§†åŒ–å·¥å…· â­â­â­

**ç›®æ ‡**: åˆ›å»ºä¸€ä¸ªå¯è§†åŒ–å·¥å…·ï¼Œå±•ç¤ºæ‰©æ•£è¿‡ç¨‹

**ä»»åŠ¡**:
1. è®°å½•æ¯æ¬¡è¿­ä»£çš„çŠ¶æ€ï¼ˆå“ªäº› token æ˜¯ MASKï¼Œå“ªäº›è¢«è§£ç ï¼‰
2. ç”ŸæˆåŠ¨ç”»ï¼Œå±•ç¤ºè§£ç è¿‡ç¨‹
3. åˆ†æä¸åŒä½ç½®çš„è§£ç é€Ÿåº¦

**å®ç°æ¡†æ¶**:
```python
import matplotlib.pyplot as plt
import matplotlib.animation as animation

class DiffusionVisualizer:
    def __init__(self):
        self.history = []  # å­˜å‚¨æ¯æ¬¡è¿­ä»£çš„çŠ¶æ€
    
    def record(self, x, mask_index, iteration):
        """è®°å½•å½“å‰çŠ¶æ€"""
        self.history.append({
            'iteration': iteration,
            'tokens': x.clone(),
            'mask_index': mask_index.clone()
        })
    
    def animate(self, tokenizer, output_path='diffusion.gif'):
        """ç”ŸæˆåŠ¨ç”»"""
        fig, ax = plt.subplots(figsize=(12, 2))
        
        def update(frame):
            ax.clear()
            state = self.history[frame]
            tokens = state['tokens'][0].cpu().numpy()
            mask_idx = state['mask_index'][0].cpu().numpy()
            
            # å¯è§†åŒ–ï¼šç»¿è‰²=å·²è§£ç ï¼Œçº¢è‰²=MASK
            colors = ['green' if not m else 'red' for m in mask_idx]
            ax.bar(range(len(tokens)), [1]*len(tokens), color=colors)
            ax.set_title(f"Iteration {state['iteration']}")
            ax.set_xlabel('Position')
            ax.set_ylim(0, 1.5)
        
        ani = animation.FuncAnimation(
            fig, update, frames=len(self.history), interval=500
        )
        ani.save(output_path, writer='pillow')
        print(f"Animation saved to {output_path}")
```

**é›†æˆåˆ°æ¨ç†**:
```python
# ä¿®æ”¹ BlockWiseDiffusionLLM.generate()
visualizer = DiffusionVisualizer()

while (block == mask_id).sum() > 0:
    # ... æ‰§è¡Œè§£ç  ...
    visualizer.record(x, mask_index, iter_count)

visualizer.animate(tokenizer, 'output.gif')
```

---

### é¡¹ç›® 3: åœ¨çº¿æœåŠ¡ Demo â­â­â­

**ç›®æ ‡**: éƒ¨ç½²ä¸€ä¸ªç®€å•çš„åœ¨çº¿æ¨ç†æœåŠ¡

**ä»»åŠ¡**:
1. ä½¿ç”¨ `serving.py` ä¸­çš„ `DiffusionLLMServing`
2. åˆ›å»º FastAPI æ¥å£
3. æ”¯æŒæµå¼è¾“å‡º

**å®ç°**
:
```python
from fastapi import FastAPI
from dinfer import DiffusionLLMServing, SamplingParams

app = FastAPI()

# åˆå§‹åŒ–æœåŠ¡
serving = DiffusionLLMServing(
    model="your_model_path",
    is_moe=True,
    gpu_ids=[0, 1, 2, 3],
    use_tp=True
)

@app.post("/generate")
async def generate(prompt: str, max_length: int = 512):
    """ç”Ÿæˆæ–‡æœ¬"""
    sampling_params = SamplingParams(
        gen_length=max_length,
        block_length=32,
        threshold=0.9
    )
    
    result = serving.generate(prompt, sampling_params)
    return {"text": result}

@app.get("/health")
async def health():
    return {"status": "ok"}

# è¿è¡Œ: uvicorn server:app --host 0.0.0.0 --port 8000
```

---

## ğŸš€ è¿›é˜¶ä¸»é¢˜

### 1. ä¸å…¶ä»–æ¡†æ¶å¯¹æ¯”

**å¯¹æ¯”å®éªŒ**:
```bash
# dInfer
python benchmarks/benchmark_dataset.py \
  --model_type llada_moe \
  --output_dir runs/dinfer

# Fast-dLLMï¼ˆæ¡†æ¶å†…ç½®å¯¹æ¯”ï¼‰
python benchmarks/benchmark_dataset_fastdllm.py \
  --model_type llada \
  --output_dir runs/fastdllm

# SGLangï¼ˆæ¡†æ¶å†…ç½®å¯¹æ¯”ï¼‰
python benchmarks/benchmark_dataset_sglang.py \
  --model_type llada2 \
  --output_dir runs/sglang
```

**åˆ†æç»´åº¦**:
- TPS (Tokens Per Second)
- å»¶è¿Ÿ (Latency)
- å†…å­˜ä½¿ç”¨ (Memory Usage)
- ç”Ÿæˆè´¨é‡ (Quality)

---

### 2. æºç è´¡çŒ®æŒ‡å—

å¦‚æœä½ æƒ³ä¸º dInfer è´¡çŒ®ä»£ç ï¼š

**æ­¥éª¤**:
1. Fork ä»“åº“
2. åˆ›å»ºåˆ†æ”¯: `git checkout -b feature/my-feature`
3. ç¼–å†™ä»£ç å’Œæµ‹è¯•
4. æäº¤ PR

**ä»£ç è§„èŒƒ**:
- éµå¾ª PEP 8
- æ·»åŠ ç±»å‹æ³¨è§£
- ç¼–å†™æ–‡æ¡£å­—ç¬¦ä¸²
- æ·»åŠ å•å…ƒæµ‹è¯•

**æµ‹è¯•**:
```bash
# è¿è¡Œæµ‹è¯•
pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_llada_moe.py -v
```

---

### 3. æ‰©å±•é˜…è¯»

**è®ºæ–‡**:
- dInfer æŠ€æœ¯æŠ¥å‘Š: https://arxiv.org/abs/2510.08666
- LLaDA: Latent Diffusion for Language Models
- DDPM: Denoising Diffusion Probabilistic Models
- OLMoE: Mixture-of-Experts in Open Language Models

**ç›¸å…³é¡¹ç›®**:
- vLLM: https://github.com/vllm-project/vllm
- SGLang: https://github.com/sgl-project/sglang
- Fast-dLLM: (æŸ¥çœ‹ dInfer å¯¹æ¯”å®ç°)

---

## â“ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆéœ€è¦è½¬æ¢ MoE æ¨¡å‹ä¸º FusedMoEï¼Ÿ

**A**: èåˆ MoE å¯ä»¥ï¼š
- å‡å°‘å†…å­˜ç¢ç‰‡
- æé«˜ä¸“å®¶è®¡ç®—æ•ˆç‡
- æ›´å¥½æ”¯æŒ Expert Parallel

ä½¿ç”¨ `tools/transfer.py` è¿›è¡Œè½¬æ¢ã€‚

---

### Q2: å¦‚ä½•é€‰æ‹©åˆé€‚çš„é˜ˆå€¼ï¼ˆthresholdï¼‰ï¼Ÿ

**A**: 
- **é«˜é˜ˆå€¼ï¼ˆ0.9-0.95ï¼‰**: é«˜è´¨é‡ï¼Œä½†é€Ÿåº¦è¾ƒæ…¢
- **ä¸­é˜ˆå€¼ï¼ˆ0.8-0.85ï¼‰**: å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡
- **ä½é˜ˆå€¼ï¼ˆ0.7-0.75ï¼‰**: é«˜é€Ÿåº¦ï¼Œä½†è´¨é‡å¯èƒ½ä¸‹é™

å»ºè®®ï¼šæ ¹æ®ä»»åŠ¡éœ€æ±‚è°ƒä¼˜ã€‚

---

### Q3: å—å¤§å°ï¼ˆblock_lengthï¼‰å¦‚ä½•å½±å“æ€§èƒ½ï¼Ÿ

**A**:
- **å°å—ï¼ˆ16-32ï¼‰**: æ›´é¢‘ç¹çš„ KV-Cache æ›´æ–°ï¼Œé€‚åˆçŸ­æ–‡æœ¬
- **å¤§å—ï¼ˆ64-128ï¼‰**: æ›´å°‘çš„ KV-Cache æ›´æ–°ï¼Œé€‚åˆé•¿æ–‡æœ¬

LLaDA-MoE æ¨è: 64
LLaDA2 æ¨è: 32

---

### Q4: Dual Cache å’Œ Prefix Cache æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**A**:
- **Prefix Cache**: åªç¼“å­˜å›ºå®šå‰ç¼€ï¼Œé€‚åˆ prompt ä¸å˜çš„åœºæ™¯
- **Dual Cache**: åŒç¼“å­˜ç­–ç•¥ï¼Œå½“å‰å— + å†å²ç¼“å­˜ï¼Œæ›´çµæ´»ä½†å†…å­˜å¼€é”€æ›´å¤§

---

### Q5: ä¸ºä»€ä¹ˆ LLaDA2 åªæ”¯æŒ 4-way TPï¼Ÿ

**A**: LLaDA2 åªæœ‰ 4 ä¸ªæ³¨æ„åŠ›å¤´ï¼ˆattention headsï¼‰ï¼Œå› æ­¤æœ€å¤šåªèƒ½åˆ‡åˆ†åˆ° 4 ä¸ª GPUã€‚å¦‚éœ€æ›´å¤§å¹¶è¡Œåº¦ï¼Œå¯ä½¿ç”¨ LLaDA-MoEï¼ˆæ”¯æŒ 8-way TPï¼‰ã€‚

---

### Q6: å¦‚ä½•è°ƒè¯•æ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜ï¼Ÿ

**A**:
1. æ£€æŸ¥æ˜¯å¦å¯ç”¨ PyTorch ç¼–è¯‘: `--use_compile`
2. æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ TP: `--use_tp`
3. æ£€æŸ¥ batch size æ˜¯å¦åˆé€‚
4. ä½¿ç”¨ `nvidia-smi` æ£€æŸ¥ GPU åˆ©ç”¨ç‡
5. ä½¿ç”¨ PyTorch Profiler åˆ†æç“¶é¢ˆ

---

### Q7: èƒ½å¦åœ¨ CPU ä¸Šè¿è¡Œï¼Ÿ

**A**: dInfer ä¾èµ– CUDA å’Œ NCCLï¼Œç›®å‰ä¸æ”¯æŒçº¯ CPU æ¨ç†ã€‚æœ€ä½è¦æ±‚ 1 ä¸ª GPUã€‚

---

## ğŸ“ å­¦ä¹ æ£€æŸ¥æ¸…å•

### åŸºç¡€çŸ¥è¯† âœ…
- [ ] ç†è§£æ‰©æ•£æ¨¡å‹çš„åŸºæœ¬åŸç†
- [ ] ç†è§£ dLLM ä¸è‡ªå›å½’ LLM çš„åŒºåˆ«
- [ ] ç†è§£å¹¶è¡Œè§£ç çš„æ¦‚å¿µ
- [ ] æˆåŠŸè¿è¡Œç¬¬ä¸€ä¸ªæ¨ç†ç¤ºä¾‹

### è§£ç é€»è¾‘ âœ…
- [ ] ç†è§£ `TokenArray` å’Œ `BlockIterator` çš„ä½œç”¨
- [ ] ç†è§£ Thresholdã€Hierarchyã€Credit è§£ç ç­–ç•¥
- [ ] ç†è§£ KV-Cache ç®¡ç†æœºåˆ¶
- [ ] èƒ½å¤Ÿé˜…è¯» `generate_uniform.py` çš„ä¸»æµç¨‹

### æ¨¡å‹å®ç° âœ…
- [ ] ç†è§£ LLaDA æ¨¡å‹æ¶æ„
- [ ] ç†è§£ MoE çš„è·¯ç”±å’Œä¸“å®¶æœºåˆ¶
- [ ] ç†è§£ LLaDA2 çš„å—æ‰©æ•£æœºåˆ¶
- [ ] ç†è§£å¼ é‡å¹¶è¡Œå’Œä¸“å®¶å¹¶è¡Œ

### ç³»ç»Ÿä¼˜åŒ– âœ…
- [ ] ç†è§£ PyTorch ç¼–è¯‘ä¼˜åŒ–
- [ ] ç†è§£ CUDA Graphs
- [ ] ç†è§£å¾ªç¯å±•å¼€ä¼˜åŒ–
- [ ] èƒ½å¤Ÿåˆ†ææ€§èƒ½ç“¶é¢ˆ

### å®è·µèƒ½åŠ› âœ…
- [ ] èƒ½å¤Ÿè¿è¡Œ benchmark æµ‹è¯•
- [ ] èƒ½å¤Ÿä½¿ç”¨è¯„ä¼°æ¡†æ¶
- [ ] èƒ½å¤Ÿè°ƒä¼˜è¶…å‚æ•°
- [ ] èƒ½å¤Ÿå®ç°è‡ªå®šä¹‰è§£ç ç­–ç•¥

---

## ğŸ“ æ€»ç»“

æ­å–œä½ å®Œæˆ dInfer æ¡†æ¶çš„å­¦ä¹ ï¼

**ä½ å·²ç»æŒæ¡**:
1. âœ… æ‰©æ•£è¯­è¨€æ¨¡å‹çš„æ ¸å¿ƒåŸç†
2. âœ… dInfer çš„å››å¤§ç»„ä»¶è®¾è®¡
3. âœ… å¹¶è¡Œè§£ç ç­–ç•¥çš„å®ç°
4. âœ… ç³»ç»Ÿçº§ä¼˜åŒ–æŠ€æœ¯
5. âœ… æ¨¡å‹è¯„ä¼°å’Œè°ƒä¼˜æ–¹æ³•

**ä¸‹ä¸€æ­¥å»ºè®®**:
- ğŸ”¬ åœ¨å®é™…é¡¹ç›®ä¸­åº”ç”¨ dInfer
- ğŸ“ ä¸ºç¤¾åŒºè´¡çŒ®ä»£ç æˆ–æ–‡æ¡£
- ğŸš€ æ¢ç´¢æ–°çš„è§£ç ç®—æ³•
- ğŸ“Š åœ¨æ›´å¤š benchmark ä¸Šæµ‹è¯•

**åŠ å…¥ç¤¾åŒº**:
- GitHub: https://github.com/inclusionAI/dInfer
- å¾®ä¿¡ç¾¤: è§ README.md ä¸­çš„äºŒç»´ç 
- æŠ€æœ¯æŠ¥å‘Š: https://arxiv.org/abs/2510.08666

---

**Happy Coding! ğŸ‰**